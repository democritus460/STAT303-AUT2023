
@incollection{green_innovative_2019,
	title = {The {Innovative} {City}: {The} {Relationship} between {Technical} and {Nontechnical} {Change} in {City} {Government}},
	shorttitle = {The {Innovative} {City}},
	url = {https://direct.mit.edu/books/book/4204/chapter/172388/The-Innovative-City-The-Relationship-between},
	language = {en},
	urldate = {2021-05-03},
	booktitle = {The {Smart} {Enough} {City}: {Putting} {Technology} in {Its} {Place} to {Reclaim} {Our} {Urban} {Future}},
	author = {Green, Ben},
	month = apr,
	year = {2019},
	file = {Green_2019_The Innovative City.pdf:/Users/pgao/Zotero/storage/Q6Q78EBJ/Green_2019_The Innovative City.pdf:application/pdf},
}

@article{mullainathan_biased_2019,
	chapter = {Business},
	title = {Biased {Algorithms} {Are} {Easier} to {Fix} {Than} {Biased} {People}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html},
	abstract = {Racial discrimination by algorithms or by people is harmful — but that’s where the similarities end.},
	language = {en-US},
	urldate = {2021-12-21},
	journal = {The New York Times},
	author = {Mullainathan, Sendhil},
	month = dec,
	year = {2019},
	keywords = {Photography, Discrimination, Race and Ethnicity, Brigham and Women's Hospital, Careers and Professions, Computers and the Internet, Economics (Theory and Philosophy), Hiring and Promotion, Labor and Jobs, Massachusetts General Hospital, Regulation and Deregulation of Industry, Science (Journal), University of California, Berkeley},
	file = {Mullainathan_2019_Biased Algorithms Are Easier to Fix Than Biased People.pdf:/Users/pgao/Zotero/storage/LPW6CMA6/Mullainathan_2019_Biased Algorithms Are Easier to Fix Than Biased People.pdf:application/pdf},
}

@inproceedings{green_false_2020,
	address = {New York, NY, USA},
	series = {{FAT}* '20},
	title = {The false promise of risk assessments: epistemic reform and the limits of fairness},
	isbn = {978-1-4503-6936-7},
	shorttitle = {The false promise of risk assessments},
	url = {https://doi.org/10.1145/3351095.3372869},
	doi = {10.1145/3351095.3372869},
	abstract = {Risk assessments have proliferated in the United States criminal justice system. The theory of change motivating their adoption involves two key assumptions: first, that risk assessments will reduce human biases by making objective decisions, and second, that risk assessments will promote criminal justice reform. In this paper I interrogate both of these assumptions, concluding that risk assessments are an ill-advised tool for challenging the centrality and legitimacy of incarceration within the criminal justice system. First, risk assessments fail to provide objectivity, as their use creates numerous sites of discretion. Second, risk assessments provide no guarantee of reducing incarceration; instead, they risk legitimizing the criminal justice system's structural racism. I then consider, via an "epistemic reform," the path forward for criminal justice reform. I reinterpret recent results regarding the "impossibility of fairness" as not simply a tension between mathematical metrics but as evidence of a deeper tension between notions of equality. This expanded frame challenges the formalist, colorblind proceduralism at the heart of the criminal justice system and suggests a more structural approach to reform. Together, this analysis highlights how algorithmic fairness narrows the scope of judgments about justice and how "fair" algorithms can reinforce discrimination.},
	urldate = {2021-03-24},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Green, Ben},
	month = jan,
	year = {2020},
	keywords = {fairness, risk assessment, criminal justice system, social justice},
	pages = {594--606},
	file = {Green - 2020 - The false promise of risk assessments epistemic r.pdf:/Users/pgao/Zotero/storage/W245D8SQ/Green - 2020 - The false promise of risk assessments epistemic r.pdf:application/pdf},
}

@misc{jeffrey_mervis_can_2019,
	title = {Can a set of equations keep {U}.{S}. census data private?},
	url = {https://www.science.org/content/article/can-set-equations-keep-us-census-data-private},
	abstract = {Census Bureau embraces differential privacy in latest attempt to ensure confidentiality without sacrificing data quality},
	language = {en},
	urldate = {2021-12-21},
	journal = {ScienceInsider},
	author = {Mervis, Jeffery},
	month = jan,
	year = {2019},
}

@article{lum_predict_2016,
	title = {To predict and serve?},
	volume = {13},
	copyright = {© 2016 The Royal Statistical Society},
	issn = {1740-9713},
	url = {http://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1740-9713.2016.00960.x},
	doi = {https://doi.org/10.1111/j.1740-9713.2016.00960.x},
	abstract = {Predictive policing systems are used increasingly by law enforcement to try to prevent crime before it occurs. But what happens when these systems are trained using biased data? Kristian Lum and William Isaac consider the evidence – and the social consequences},
	number = {5},
	urldate = {2021-06-01},
	journal = {Significance},
	author = {Lum, Kristian and Isaac, William},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740-9713.2016.00960.x},
	pages = {14--19},
	file = {Lum and Isaac - 2016 - To predict and serve.pdf:/Users/pgao/Zotero/storage/ZDRFWECP/Lum and Isaac - 2016 - To predict and serve.pdf:application/pdf},
}

@article{raji_thats_2019,
	title = {That's not fair!},
	volume = {25},
	issn = {1528-4972},
	url = {https://doi-org.offcampus.lib.washington.edu/10.1145/3313127},
	doi = {10.1145/3313127},
	abstract = {Why we need to study machine learning fairness, even in an increasingly unfair world.},
	number = {3},
	urldate = {2021-12-20},
	journal = {XRDS: Crossroads, The ACM Magazine for Students},
	author = {Raji, Deborah},
	month = apr,
	year = {2019},
	pages = {44--48},
	file = {Full Text PDF:/Users/pgao/Zotero/storage/G7IF5EUG/Raji - 2019 - That's not fair!.pdf:application/pdf},
}

@article{lum_what_2021,
	title = {What is an “algorithm”? {It} depends whom you ask},
	url = {https://www.technologyreview.com/2021/02/26/1020007/what-is-an-algorithm/},
	urldate = {2021-04-26},
	journal = {MIT Technology Review},
	author = {Lum, Kristian and Chowdhury, Rumman},
	month = feb,
	year = {2021},
	file = {Lum and Chowdhury - 2021 - What is an “algorithm” It depends whom you ask.pdf:/Users/pgao/Zotero/storage/8MY7BXVK/Lum and Chowdhury - 2021 - What is an “algorithm” It depends whom you ask.pdf:application/pdf},
}

@article{kalluri2020,
	title = {Don{\textquoteright}t ask if artificial intelligence is good or fair, ask how it shifts power},
	author = {Kalluri, Pratyusha},
	year = {2020},
	month = {07},
	date = {2020-07-07},
	journal = {Nature},
	pages = {169--169},
	volume = {583},
	number = {7815},
	doi = {10.1038/d41586-020-02003-2},
	url = {https://www.nature.com/articles/d41586-020-02003-2},
	note = {Number: 7815
Publisher: Nature Publishing Group},
	langid = {en}
}

@misc{alleninstituteforai2021,
	title = {Ask Delphi},
	author = {Allen Institute for AI, },
	year = {2021},
	date = {2021},
	url = {https://delphi.allenai.org/}
}

@misc{bonde2013,
	title = {A Framework for Making Ethical Decisions},
	author = {Bonde, Sheila and Firenze, Paul},
	year = {2013},
	month = {05},
	date = {2020-02-18},
	url = {https://web.archive.org/web/20200218064417/https://www.brown.edu/academics/science-and-technology-studies/framework-making-ethical-decisions}
}

@article{gupta2020,
	title = {AI ethics groups are repeating one of society{\textquoteright}s classic mistakes},
	author = {Gupta, Abhishek and Heath, Victoria},
	year = {2020},
	month = {09},
	date = {2020-09-14},
	journal = {MIT Technology Review.com},
	url = {https://www.proquest.com/other-sources/ai-ethics-groups-are-repeating-one-society-s/docview/2820955494/se-2?accountid=14784},
	note = {\url{https://www.technologyreview.com/2020/09/14/1008323/ai-ethics-representation-artificial-intelligence-opinion/}},
	langid = {en}
}

@misc{jiang2021,
	title = {Towards Machine Ethics and Norms},
	author = {Jiang, Liwei},
	year = {2021},
	month = {11},
	date = {2021-11-04},
	url = {https://medium.com/ai2-blog/towards-machine-ethics-and-norms-d64f2bdde6a3},
	langid = {en}
}

@misc{acluofwashington2021,
	title = {Automated Decision Making Systems Are Making Some of the Most Important Life Decisions For You, but You Might Not Even Know It},
	author = {ACLU of Washington, },
	year = {2021},
	month = {09},
	date = {2021-09-22},
	url = {https://www.aclu-wa.org/story/automated-decision-making-systems-are-making-some-most-important-life-decisions-you-you-might},
	langid = {en}
}

@inbook{kearns2019,
	title = {Introduction},
	author = {Kearns, Michael and Roth, Aaron},
	year = {2019},
	date = {2019},
	booktitle = {The Ethical Algorithm: The Science of Socially Aware Algorithm Design},
	publisher = {Oxford University Press USA - OSO},
	url = {http://ebookcentral.proquest.com/lib/washington/detail.action?docID=5905172},
	address = {Oxford, UNITED STATES}
}


@article{kirchner_when_2020,
	title = {When {Zombie} {Data} {Costs} {You} a {Home}},
	url = {https://themarkup.org/locked-out/2020/10/06/zombie-criminal-records-housing-background-checks},
	abstract = {Even when people get their criminal records expunged, data brokers ensure the past keeps coming back to haunt them},
	language = {en},
	urldate = {2021-05-31},
	journal = {The Markup},
	author = {Kirchner, Lauren},
	month = oct,
	year = {2020},
	note = {Section: Locked Out},
}


@misc{bembeneck2021,
	title = {To stop algorithmic bias, we first have to define it},
	author = {Bembeneck, Emily and Nissan, Rebecca and Obermeyer, Ziad},
	year = {2021},
	month = {10},
	date = {2021-10-21},
	url = {https://www.brookings.edu/research/to-stop-algorithmic-bias-we-first-have-to-define-it/},
	langid = {canadian}
}

@inbook{benjamin2019,
	title = {Default Discrimination},
	author = {Benjamin, Ruha},
	booktitle = {Race after {Technology}: {Abolitionist} {Tools} for the {New} {Jim} {Code}},
	year = {2019},
	date = {2019},
	publisher = {Polity Press},
	url = {http://ebookcentral.proquest.com/lib/washington/detail.action?docID=5820427},
	address = {Newark, UNITED KINGDOM}
}

@misc{chowdhury2021,
	title = {Sharing learnings about our image cropping algorithm},
	author = {Chowdhury, Rumman},
	year = {2021},
	month = {05},
	date = {2021-05-19},
	url = {https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm},
	langid = {en{\_}us}
}

@article{friedman1996,
	title = {Bias in computer systems},
	author = {Friedman, Batya and Nissenbaum, Helen},
	year = {1996},
	month = {07},
	date = {1996-07-01},
	journal = {ACM Transactions on Information Systems},
	pages = {330{\textendash}347},
	volume = {14},
	number = {3},
	doi = {10.1145/230538.230561},
	url = {http://doi.org/10.1145/230538.230561}
}

@article{vox2021,
	title = {Are We Automating Racism?},
	author = {Vox, },
	year = {2021},
	month = {03},
	date = {2021-03-31},
	url = {https://www.youtube.com/watch?v=Ok5sKLXqynQ}
}

@misc{feathers2021,
	title = {Police Are Telling ShotSpotter to Alter Evidence From Gunshot-Detecting AI},
	author = {Feathers, Todd},
	year = {2021},
	month = {07},
	date = {2021-07-26},
	url = {https://www.vice.com/en/article/qj8xbq/police-are-telling-shotspotter-to-alter-evidence-from-gunshot-detecting-ai},
	langid = {en}
}

@article{mitchell2021,
	title = {Algorithmic Fairness: Choices, Assumptions, and Definitions},
	author = {Mitchell, Shira and Potash, Eric and Barocas, Solon and {D{\textquoteright}Amour}, Alexander and Lum, Kristian},
	year = {2021},
	date = {2021},
	journal = {Annual Review of Statistics and Its Application},
	pages = {null},
	volume = {8},
	number = {1},
	doi = {10.1146/annurev-statistics-042720-125902},
	url = {https://doi.org/10.1146/annurev-statistics-042720-125902}
}

@article{smith2021,
	title = {How TikTok Reads Your Mind},
	author = {Smith, Ben},
	year = {2021},
	month = {12},
	date = {2021-12-06},
	journal = {The New York Times},
	url = {https://www.nytimes.com/2021/12/05/business/media/tiktok-algorithm.html},
	langid = {canadian}
}

@article{jeffries2020,
	title = {Swinging the Vote?},
	author = {Jeffries, Adrianne and Yin, Leon and Mattu, Surya},
	year = {2020},
	month = {02},
	date = {2020-02-26},
	journal = {The Markup},
	url = {https://themarkup.org/google-the-giant/2020/02/26/wheres-my-email},
	note = {Section: News},
	langid = {en}
}

@article{kirchner2020,
	title = {When Zombie Data Costs You a Home},
	author = {Kirchner, Lauren},
	year = {2020},
	month = {10},
	date = {2020-10-06},
	journal = {The Markup},
	url = {https://themarkup.org/locked-out/2020/10/06/zombie-criminal-records-housing-background-checks},
	note = {Section: Locked Out},
	langid = {en}
}

@article{varner2020,
	title = {Suckers List: How Allstate{\textquoteright}s Secret Auto Insurance Algorithm Squeezes Big Spenders},
	author = {Varner, Maddy and Sankin, Aaron},
	year = {2020},
	month = {02},
	date = {2020-02-25},
	journal = {The Markup},
	url = {https://themarkup.org/allstates-algorithm/2020/02/25/car-insurance-suckers-list},
	note = {Section: News},
	langid = {en}
}

@article{fry2019,
	title = {What Statistics Can and Can{\textquoteright}t Tell Us About Ourselves},
	author = {Fry, Hannah},
	year = {2019},
	month = {09},
	date = {2019-09-02},
	journal = {The New Yorker},
	url = {https://www.newyorker.com/magazine/2019/09/09/what-statistics-can-and-cant-tell-us-about-ourselves},
	langid = {en-us}
}

@misc{ochigame2020,
	title = {The Long History of Algorithmic Fairness},
	author = {Ochigame, Rodrigo},
	year = {2020},
	month = {01},
	date = {2020-01-30},
	url = {https://phenomenalworld.org/analysis/long-history-algorithmic-fairness}
}

@misc{onuoha2020,
	title = {When Proof Is Not Enough},
	author = {Onuoha, Mimi},
	year = {2020},
	month = {07},
	date = {2020-07-01},
	url = {https://fivethirtyeight.com/features/when-proof-is-not-enough/},
	langid = {canadian}
}

@article{whitby2020,
	title = {A Brief History of the Census{\textemdash}and How Covid-19 Could Change It},
	author = {Whitby, Andrew},
	year = {2020},
	month = {04},
	date = {2020-04-01},
	journal = {Wired},
	url = {https://www.wired.com/story/brief-history-census-how-covid-19-could-change-it/},
	langid = {en-us}
}

@article{buolamwini2020,
	title = {Facial Recognition Technologies: A Primer},
	author = {Buolamwini, Joy and {Ordóñez}, Vicente and Morgenstern, Jamie and Learned-Miller, Erik},
	year = {2020},
	month = {05},
	date = {2020-05-29},
	url = {https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5ed1002058516c11edc66a14_FRTsPrimerMay2020.pdf}
}

@article{hill2019,
	title = {How Photos of Your Kids Are Powering Surveillance Technology},
	author = {Hill, Kashmir and Krolik, Aaron},
	year = {2019},
	month = {10},
	date = {2019-10-11},
	journal = {The New York Times},
	url = {https://www.nytimes.com/interactive/2019/10/11/technology/flickr-facial-recognition.html},
	langid = {canadian}
}

@misc{mcvean2019,
	title = {40 Years of Human Experimentation in America: The Tuskegee Study},
	author = {McVean, Ada},
	year = {2019},
	month = {01},
	date = {2019-01-25},
	url = {https://www.mcgill.ca/oss/article/history/40-years-human-experimentation-america-tuskegee-study},
	langid = {en}
}

@inproceedings{buolamwini2018,
	title = {Conference on Fairness, Accountability and Transparency},
	author = {Buolamwini, Joy and Gebru, Timnit},
	year = {2018},
	month = {01},
	date = {2018-01-21},
	publisher = {PMLR},
	pages = {77--91},
	url = {http://proceedings.mlr.press/v81/buolamwini18a.html},
	note = {ISSN: 2640-3498},
	langid = {en}
}

@article{castelvecchi2020,
	title = {Is facial recognition too biased to be let loose?},
	author = {Castelvecchi, Davide},
	year = {2020},
	month = {11},
	date = {2020-11-18},
	journal = {Nature},
	pages = {347--349},
	volume = {587},
	number = {7834},
	doi = {10.1038/d41586-020-03186-4},
	url = {https://www.nature.com/articles/d41586-020-03186-4},
	note = {Number: 7834
Publisher: Nature Publishing Group},
	langid = {en}
}

@article{mitmedialab2018,
	title = {Gender Shades},
	author = {MIT Media Lab, },
	year = {2018},
	month = {02},
	date = {2018-02-09},
	url = {https://www.youtube.com/watch?v=TWWsW1w-BVo}
}

@article{noorden2020,
	title = {The ethical questions that haunt facial-recognition research},
	author = {Noorden, Richard Van},
	year = {2020},
	month = {11},
	date = {2020-11-18},
	journal = {Nature},
	pages = {354--358},
	volume = {587},
	number = {7834},
	doi = {10.1038/d41586-020-03187-3},
	url = {https://www.nature.com/articles/d41586-020-03187-3},
	note = {Number: 7834
Publisher: Nature Publishing Group},
	langid = {en}
}

@misc{angwin2016,
	title = {Machine Bias},
	author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
	year = {2016},
	month = {05},
	date = {2016-05-23},
	url = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing?token=jRdnwabwdw5HLiHY-R3nqWS5DOjEM7W-},
	langid = {en}
}

@article{hill2020,
	title = {Wrongfully Accused by an Algorithm},
	author = {Hill, Kashmir},
	year = {2020},
	month = {06},
	date = {2020-06-24},
	journal = {The New York Times},
	url = {https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html},
	langid = {canadian}
}

@article{oneill2019,
	title = {How Facial Recognition Makes You Safer},
	author = {{O{\textquoteright}Neill}, James},
	year = {2019},
	month = {06},
	date = {2019-06-09},
	journal = {The New York Times},
	url = {https://www.nytimes.com/2019/06/09/opinion/facial-recognition-police-new-york-city.html},
	langid = {canadian}
}

@article{arvindnarayanan2018,
	title = {Tutorial: 21 fairness definitions and their politics},
	author = {Arvind Narayanan, },
	year = {2018},
	month = {03},
	date = {2018-03-01},
	url = {https://www.youtube.com/watch?v=jIXIuYdnyyk}
}

@article{chouldechova2017,
	title = {Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments},
	author = {Chouldechova, Alexandra},
	year = {2017},
	month = {06},
	date = {2017-06-01},
	journal = {Big Data},
	pages = {153--163},
	volume = {5},
	number = {2},
	doi = {10.1089/big.2016.0047},
	url = {https://www.liebertpub.com/doi/abs/10.1089/big.2016.0047},
	note = {Publisher: Mary Ann Liebert, Inc., publishers}
}

@inbook{crawford2021,
	title = {State},
	author = {Crawford, Kate},
	year = {2021},
	date = {2021},
	publisher = {Yale University Press},
	pages = {181--209},
	series = {Power, Politics, and the Planetary Costs of Artificial Intelligence},
	doi = {10.2307/j.ctv1ghv45t.9},
	url = {https://www.jstor.org/stable/j.ctv1ghv45t.9},
	note = {DOI: 10.2307/j.ctv1ghv45t.9}
}

@article{kirchner2021,
	title = {Powerful DNA Software Used in Hundreds of Criminal Cases Faces New Scrutiny},
	author = {Kirchner, Lauren},
	year = {2021},
	month = {03},
	date = {2021-03-09},
	journal = {The Markup},
	url = {https://themarkup.org/news/2021/03/09/powerful-dna-software-used-in-hundreds-of-criminal-cases-faces-new-scrutiny},
	note = {Section: News},
	langid = {en}
}

@misc{ingold2016,
	title = {Amazon Doesn{\textquoteright}t Consider the Race of Its Customers. Should It?},
	author = {Ingold, David and Soper, Spencer},
	year = {2016},
	month = {04},
	date = {2016-04-21},
	url = {http://www.bloomberg.com/graphics/2016-amazon-same-day/},
	langid = {en}
}

@article{mittechnologyreview2021,
	title = {Podcast: In Machines We Trust - Hired by an algorithm},
	author = {MIT Technology Review, },
	year = {2021},
	month = {06},
	date = {2021-06-23},
	url = {https://www.youtube.com/watch?v=ztcVB_zh_M0}
}

@misc{raghavan2019,
	title = {Challenges for mitigating bias in algorithmic hiring},
	author = {Raghavan, Manish and Barocas, Solon},
	year = {2019},
	month = {12},
	date = {2019-12-06},
	url = {https://www.brookings.edu/research/challenges-for-mitigating-bias-in-algorithmic-hiring/},
	langid = {canadian}
}

@misc{booth2020,
	title = {Uber drivers to launch legal bid to uncover app's algorithm},
	author = {Booth, Robert},
	year = {2020},
	month = {07},
	date = {2020-07-20},
	url = {http://www.theguardian.com/technology/2020/jul/20/uber-drivers-to-launch-legal-bid-to-uncover-apps-algorithm},
	note = {Section: Technology},
	langid = {en}
}

@misc{gurley2021,
	title = {Amazon Drivers Are Instructed to Drive Recklessly to Meet Delivery Quotas},
	author = {Gurley, Lauren Kaori},
	year = {2021},
	month = {05},
	date = {2021-05-06},
	url = {https://www.vice.com/en/article/xgxx54/amazon-drivers-are-instructed-to-drive-recklessly-to-meet-delivery-quotas},
	langid = {en}
}

@misc{thefinancialtimes2020,
	title = {The Uber Game},
	author = {The Financial Times, },
	year = {2020},
	date = {2020},
	url = {https://ig.ft.com/uber-game},
	langid = {australian}
}

@article{eubanks2018,
	title = {A Child Abuse Prediction Model Fails Poor Families},
	author = {Eubanks, Virginia},
	year = {2018},
	month = {01},
	date = {2018-01-15},
	journal = {Wired},
	url = {https://www.wired.com/story/excerpt-from-automating-inequality/},
	langid = {canadian}
}

@techreport{gilman2020,
	title = {Poverty Lawgorithms},
	author = {Gilman, Michele},
	year = {2020},
	month = {09},
	date = {2020-09-15},
	url = {https://datasociety.net/library/poverty-lawgorithms/},
	langid = {canadian}
}

@article{henriques-gomes2019,
	title = {The automated system leaving welfare recipients cut off with nowhere to turn},
	author = {Henriques-Gomes, Luke},
	year = {2019},
	month = {10},
	date = {2019-10-16},
	journal = {the Guardian},
	url = {http://www.theguardian.com/technology/2019/oct/16/automated-messages-welfare-australia-system},
	langid = {en}
}

@misc{sudhir2020,
	title = {What Happens When a Billion Identities Are Digitized?},
	author = {Sudhir, K. and Sunder, Shyam},
	year = {2020},
	month = {03},
	date = {2020-03-27},
	url = {https://insights.som.yale.edu/insights/what-happens-when-billion-identities-are-digitized},
	langid = {en}
}

@article{chen2021,
	title = {Ethical Machine Learning in Healthcare},
	author = {Chen, Irene Y. and Pierson, Emma and Rose, Sherri and Joshi, Shalmali and Ferryman, Kadija and Ghassemi, Marzyeh},
	year = {2021},
	date = {2021},
	journal = {Annual Review of Biomedical Data Science},
	pages = {null},
	volume = {4},
	number = {1},
	doi = {10.1146/annurev-biodatasci-092820-114757},
	url = {https://doi.org/10.1146/annurev-biodatasci-092820-114757},
	note = {{\_}eprint: https://doi.org/10.1146/annurev-biodatasci-092820-114757}
}

@article{obermeyer2019,
	title = {Dissecting racial bias in an algorithm used to manage the health of populations},
	author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
	year = {2019},
	month = {10},
	date = {2019-10-25},
	journal = {Science},
	pages = {447--453},
	volume = {366},
	number = {6464},
	doi = {10.1126/science.aax2342},
	url = {https://science-sciencemag-org.offcampus.lib.washington.edu/content/366/6464/447},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article
PMID: 31649194},
	langid = {en}
}

@misc{jeffreymervis2019,
	title = {Can a set of equations keep U.S. census data private?},
	author = {Jeffrey Mervis, },
	year = {2019},
	month = {01},
	date = {2019-01-04},
	url = {https://www.science.org/content/article/can-set-equations-keep-us-census-data-private},
	langid = {en}
}

@article{wezerek2020,
	title = {Opinion | Changes to the Census Could Make Small Towns Disappear},
	author = {Wezerek, Gus and Riper, David Van},
	year = {2020},
	month = {02},
	date = {2020-02-06},
	journal = {The New York Times},
	url = {https://www.nytimes.com/interactive/2020/02/06/opinion/census-algorithm-privacy.html},
	langid = {canadian}
}

@misc{wolford2018,
	title = {What is GDPR, the EU{\textquoteright}s new data protection law?},
	author = {Wolford, Ben},
	year = {2018},
	month = {11},
	date = {2018-11-07},
	url = {https://gdpr.eu/what-is-gdpr/},
	note = {Section: GDPR Overview},
	langid = {canadian}
}

@article{wood2018,
	title = {Differential Privacy: A Primer for a Non-Technical Audience},
	author = {Wood, Alexandra and Altman, Micah and Bembenek, Aaron and Bun, Mark and Gaboardi, Marco and Honaker, James and Nissim, Kobbi and {O'Brien}, David and Steinke, Thomas and Vadhan, Salil},
	year = {2018},
	date = {2018},
	journal = {SSRN Electronic Journal},
	doi = {10.2139/ssrn.3338027},
	url = {https://www.ssrn.com/abstract=3338027},
	langid = {en}
}

@article{hooker2021,
	title = {Moving beyond {\textquotedblleft}algorithmic bias is a data problem{\textquotedblright}},
	author = {Hooker, Sara},
	year = {2021},
	month = {04},
	date = {2021-04-09},
	journal = {Patterns},
	volume = {2},
	number = {4},
	doi = {10.1016/j.patter.2021.100241},
	url = {https://www.cell.com/patterns/abstract/S2666-3899(21)00061-1},
	note = {Publisher: Elsevier},
	langid = {English}
}

@inproceedings{raji2019,
	title = {Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products},
	author = {Raji, Inioluwa Deborah and Buolamwini, Joy},
	year = {2019},
	month = {01},
	date = {2019-01-27},
	publisher = {Association for Computing Machinery},
	pages = {429{\textendash}435},
	series = {AIES '19},
	doi = {10.1145/3306618.3314244},
	url = {https://doi.org/10.1145/3306618.3314244},
	address = {New York, NY, USA}
}

@article{upchurch2018,
	title = {To work for society, data scientists need a hippocratic oath with teeth},
	author = {Upchurch, Tom},
	journal = {Wired UK},
	year = {2018},
	url = {https://www.wired.co.uk/article/data-ai-ethics-hippocratic-oath-cathy-o-neil-weapons-of-math-destruction},
	langid = {australian}
}

@article{campbell2018,
	title = {How tech employees are pushing Silicon Valley to put ethics before profit},
	author = {Campbell, {Alexia Fernández}},
	year = {2018},
	month = {10},
	date = {2018-10-18},
	journal = {Vox},
	url = {https://www.vox.com/technology/2018/10/18/17989482/google-amazon-employee-ethics-contracts},
	langid = {en}
}

@article{heilweil2020,
	title = {Facebook is taking a hard look at racial bias in its algorithms},
	author = {Heilweil, Rebecca},
	year = {2020},
	month = {07},
	date = {2020-07-22},
	journal = {Vox},
	url = {https://www.vox.com/recode/2020/7/22/21334051/facebook-news-feed-instagram-algorithm-racial-bias-civil-rights-audit},
	langid = {en}
}

@article{nickelsburg2021,
	title = {Washington state lawmakers seek to ban government from using discriminatory AI tech},
	author = {NIckelsburg, Monica},
	year = {2021},
	month = {02},
	date = {2021-02-13},
	journal = {GeekWire},
	url = {https://www.geekwire.com/2021/washington-state-lawmakers-seek-ban-government-using-ai-tech-discriminates/},
	langid = {canadian}
}

@techreport{richardson2019,
	title = {Confronting Black Boxes: A Shadow Report of the New York City Automated Decision System Task Force},
	author = {Richardson, Rashida},
	year = {2019},
	month = {12},
	date = {2019-12-04},
	url = {https://ainowinstitute.org/ads-shadowreport-2019.html}
}

@misc{stabilit,
	title = {stability-ai/stable-diffusion {\textendash} Run with an API on Replicate},
	url = {https://replicate.com/stability-ai/stable-diffusion}
}

@misc{stabilityai,
	title = {Stable Diffusion - a Hugging Face Space},
	author = {stabilityai, },
	url = {https://huggingface.co/spaces/stabilityai/stable-diffusion}
}

@misc{baio2022,
	title = {Exploring 12 Million of the 2.3 Billion Images Used to Train Stable Diffusion's Image Generator},
	author = {Baio, Andy},
	year = {2022},
	month = {08},
	date = {2022-08-30},
	url = {https://waxy.org/2022/08/exploring-12-million-of-the-images-used-to-train-stable-diffusions-image-generator/},
	langid = {canadian}
}

@article{rudin2020,
	title = {The Age of Secrecy and Unfairness in Recidivism Prediction},
	author = {Rudin, Cynthia and Wang, Caroline and Coker, Beau},
	year = {2020},
	month = {03},
	date = {2020-03-31},
	journal = {Harvard Data Science Review},
	volume = {2},
	number = {1},
	doi = {10.1162/99608f92.6ed64b30},
	url = {https://hdsr.mitpress.mit.edu/pub/7z10o269/release/4},
	note = {Publisher: PubPub},
	langid = {en}
}

@article{chouldechova2020,
	title = {Transparency and Simplicity in Criminal Risk Assessment},
	author = {Chouldechova, Alexandra},
	year = {2020},
	month = {03},
	date = {2020-03-31},
	journal = {Harvard Data Science Review},
	volume = {2},
	number = {1},
	doi = {10.1162/99608f92.b9343eec},
	url = {https://hdsr.mitpress.mit.edu/pub/xlfiu7za/release/4},
	langid = {en}
}

@article{jackson2020,
	title = {Setting the Record Straight: What the COMPAS Core Risk and Need Assessment Is and Is Not},
	author = {Jackson, Eugenie and Mendoza, Christina},
	year = {2020},
	month = {03},
	date = {2020-03-31},
	journal = {Harvard Data Science Review},
	volume = {2},
	number = {1},
	doi = {10.1162/99608f92.1b3dadaa},
	url = {https://hdsr.mitpress.mit.edu/pub/hzwo7ax4/release/7},
	langid = {en}
}
