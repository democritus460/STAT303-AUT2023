<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.36">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STAT303 - Readings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">STAT303</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">Home</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./syllabus.html">Syllabus</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./readings.html" aria-current="page">Readings</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Readings</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<table class="table">
<thead>
<tr class="header">
<th>Date</th>
<th>Readings</th>
<th>Due</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>9/29</td>
<td><p>Allen Institute for AI. <em>Ask Delphi</em>. 2021, <a href="https://delphi.allenai.org/" class="uri">https://delphi.allenai.org/</a>.</p>
<p>Bonde, Sheila, and Paul Firenze. <em>A Framework for Making Ethical Decisions</em>. May 2013, <a href="https://www.brown.edu/academics/science-and-technology-studies/framework-making-ethical-decisions" class="uri">https://www.brown.edu/academics/science-and-technology-studies/framework-making-ethical-decisions</a>.</p>
<p>Gupta, Abhishek, and Victoria Heath. “AI Ethics Groups Are Repeating One of Society’s Classic Mistakes.” <em>MIT Technology Review</em>, Sept.&nbsp;2020, <a href="https://www.technologyreview.com/2020/09/14/1008323/ai-ethics-representation-artificial-intelligence-opinion/" class="uri">https://www.technologyreview.com/2020/09/14/1008323/ai-ethics-representation-artificial-intelligence-opinion/</a>.</p>
<p>Jiang, Liwei. “Towards Machine Ethics and Norms.” <em>AI2 Blog</em>, 4 Nov.&nbsp;2021, <a href="https://medium.com/ai2-blog/towards-machine-ethics-and-norms-d64f2bdde6a3" class="uri">https://medium.com/ai2-blog/towards-machine-ethics-and-norms-d64f2bdde6a3</a>.</p>
<p>Raji, Deborah. “That’s Not Fair!” <em>XRDS: Crossroads, The ACM Magazine for Students</em>, vol.&nbsp;25, no. 3, Apr.&nbsp;2019, pp.&nbsp;44–48. <em>Spring 2019</em>, <a href="https://doi.org/10.1145/3313127" class="uri">https://doi.org/10.1145/3313127</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>10/4</td>
<td><p>ACLU of Washington. “Automated Decision Making Systems Are Making Some of the Most Important Life Decisions For You, but You Might Not Even Know It.” <em>ACLU of Washington</em>, 22 Sept.&nbsp;2021, <a href="https://www.aclu-wa.org/story/automated-decision-making-systems-are-making-some-most-important-life-decisions-you-you-might" class="uri">https://www.aclu-wa.org/story/automated-decision-making-systems-are-making-some-most-important-life-decisions-you-you-might</a>.</p>
<p>Kearns, Michael, and Aaron Roth. “Introduction.” <em>The Ethical Algorithm: The Science of Socially Aware Algorithm Design</em>, Oxford University Press USA - OSO, 2019. <em>ProQuest Ebook Central</em>, <a href="http://ebookcentral.proquest.com/lib/washington/detail.action?docID=5905172" class="uri">http://ebookcentral.proquest.com/lib/washington/detail.action?docID=5905172</a>.</p>
<p>Lum, Kristian, and Rumman Chowdhury. “What Is an ‘Algorithm’? It Depends Whom You Ask.” <em>MIT Technology Review</em>, Feb.&nbsp;2021, <a href="https://www.technologyreview.com/2021/02/26/1020007/what-is-an-algorithm/" class="uri">https://www.technologyreview.com/2021/02/26/1020007/what-is-an-algorithm/</a>.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>10/6</td>
<td><p>Bembeneck, Emily, et al.&nbsp;“To Stop Algorithmic Bias, We First Have to Define It.” <em>Brookings</em>, 21 Oct.&nbsp;2021, <a href="https://www.brookings.edu/research/to-stop-algorithmic-bias-we-first-have-to-define-it/" class="uri">https://www.brookings.edu/research/to-stop-algorithmic-bias-we-first-have-to-define-it/</a>.</p>
<p>Benjamin, Ruha. “Default Discrimination.” <em>Race after Technology: Abolitionist Tools for the New Jim Code</em>, Polity Press, 2019. <em>ProQuest Ebook Central</em>, <a href="http://ebookcentral.proquest.com/lib/washington/detail.action?docID=5820427" class="uri">http://ebookcentral.proquest.com/lib/washington/detail.action?docID=5820427</a>.</p>
<p>Chowdhury, Rumman. <em>Sharing Learnings about Our Image Cropping Algorithm</em>. 19 May 2021, <a href="https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm" class="uri">https://blog.twitter.com/engineering/en_us/topics/insights/2021/sharing-learnings-about-our-image-cropping-algorithm</a>.</p>
<p>Friedman, Batya, and Helen Nissenbaum. “Bias in Computer Systems.” <em>ACM Transactions on Information Systems</em>, vol.&nbsp;14, no. 3, July 1996, pp.&nbsp;330–47. <em>July 1996</em>, <a href="https://doi.org/10.1145/230538.230561" class="uri">https://doi.org/10.1145/230538.230561</a>.</p>
<p>Vox. <em>Are We Automating Racism?</em> 2021. <em>YouTube</em>, <a href="https://www.youtube.com/watch?v=Ok5sKLXqynQ" class="uri">https://www.youtube.com/watch?v=Ok5sKLXqynQ</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>10/11</td>
<td><p>Feathers, Todd. <em>Police Are Telling ShotSpotter to Alter Evidence From Gunshot-Detecting AI</em>. 26 July 2021, <a href="https://www.vice.com/en/article/qj8xbq/police-are-telling-shotspotter-to-alter-evidence-from-gunshot-detecting-ai" class="uri">https://www.vice.com/en/article/qj8xbq/police-are-telling-shotspotter-to-alter-evidence-from-gunshot-detecting-ai</a>.</p>
<p>Mitchell, Shira, et al.&nbsp;“Algorithmic Fairness: Choices, Assumptions, and Definitions.” <em>Annual Review of Statistics and Its Application</em>, vol.&nbsp;8, no. 1, 2021, p.&nbsp;null. <em>Annual Reviews</em>, <a href="https://doi.org/10.1146/annurev-statistics-042720-125902" class="uri">https://doi.org/10.1146/annurev-statistics-042720-125902</a>.</p>
<p>Smith, Ben. “How TikTok Reads Your Mind.” <em>The New York Times</em>, 6 Dec.&nbsp;2021. <em>NYTimes.com</em>, <a href="https://www.nytimes.com/2021/12/05/business/media/tiktok-algorithm.html" class="uri">https://www.nytimes.com/2021/12/05/business/media/tiktok-algorithm.html</a>.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>10/13</td>
<td><p>Jeffries, Adrianne, et al.&nbsp;“Swinging the Vote?” <em>The Markup</em>, Feb.&nbsp;2020, <a href="https://themarkup.org/google-the-giant/2020/02/26/wheres-my-email" class="uri">https://themarkup.org/google-the-giant/2020/02/26/wheres-my-email</a>.</p>
<p>Kirchner, Lauren. “Powerful DNA Software Used in Hundreds of Criminal Cases Faces New Scrutiny.” <em>The Markup</em>, Mar.&nbsp;2021, <a href="https://themarkup.org/news/2021/03/09/powerful-dna-software-used-in-hundreds-of-criminal-cases-faces-new-scrutiny" class="uri">https://themarkup.org/news/2021/03/09/powerful-dna-software-used-in-hundreds-of-criminal-cases-faces-new-scrutiny</a>.</p>
<p>---. “When Zombie Data Costs You a Home.” <em>The Markup</em>, Oct.&nbsp;2020, <a href="https://themarkup.org/locked-out/2020/10/06/zombie-criminal-records-housing-background-checks" class="uri">https://themarkup.org/locked-out/2020/10/06/zombie-criminal-records-housing-background-checks</a>.</p>
<p>Varner, Maddy, and Aaron Sankin. “Suckers List: How Allstate’s Secret Auto Insurance Algorithm Squeezes Big Spenders.” <em>The Markup</em>, Feb.&nbsp;2020, <a href="https://themarkup.org/allstates-algorithm/2020/02/25/car-insurance-suckers-list" class="uri">https://themarkup.org/allstates-algorithm/2020/02/25/car-insurance-suckers-list</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>10/18</td>
<td><p>Fry, Hannah. “What Statistics Can and Can’t Tell Us About Ourselves.” <em>The New Yorker</em>, Sept.&nbsp;2019, <a href="https://www.newyorker.com/magazine/2019/09/09/what-statistics-can-and-cant-tell-us-about-ourselves" class="uri">https://www.newyorker.com/magazine/2019/09/09/what-statistics-can-and-cant-tell-us-about-ourselves</a>.</p>
<p>Ochigame, Rodrigo. “The Long History of Algorithmic Fairness.” <em>Phenomenal World</em>, 30 Jan.&nbsp;2020, <a href="https://phenomenalworld.org/analysis/long-history-algorithmic-fairness" class="uri">https://phenomenalworld.org/analysis/long-history-algorithmic-fairness</a>.</p>
<p>Onuoha, Mimi. “When Proof Is Not Enough.” <em>FiveThirtyEight</em>, 1 July 2020, <a href="https://fivethirtyeight.com/features/when-proof-is-not-enough/" class="uri">https://fivethirtyeight.com/features/when-proof-is-not-enough/</a>.</p>
<p>Whitby, Andrew. “A Brief History of the Census—and How Covid-19 Could Change It.” <em>Wired</em>, Apr.&nbsp;2020. <em>www.wired.com</em>, <a href="https://www.wired.com/story/brief-history-census-how-covid-19-could-change-it/" class="uri">https://www.wired.com/story/brief-history-census-how-covid-19-could-change-it/</a>.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>10/20</td>
<td><p>Buolamwini, Joy, et al.&nbsp;<em>Facial Recognition Technologies: A Primer</em>. 29 May 2020, <a href="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5ed1002058516c11edc66a14_FRTsPrimerMay2020.pdf" class="uri">https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5ed1002058516c11edc66a14_FRTsPrimerMay2020.pdf</a>.</p>
<p>Hill, Kashmir, and Aaron Krolik. “How Photos of Your Kids Are Powering Surveillance Technology.” <em>The New York Times</em>, 11 Oct.&nbsp;2019. <em>NYTimes.com</em>, <a href="https://www.nytimes.com/interactive/2019/10/11/technology/flickr-facial-recognition.html" class="uri">https://www.nytimes.com/interactive/2019/10/11/technology/flickr-facial-recognition.html</a>.</p>
<p>McVean, Ada. “40 Years of Human Experimentation in America: The Tuskegee Study.” <em>Office for Science and Society</em>, 25 Jan.&nbsp;2019, <a href="https://www.mcgill.ca/oss/article/history/40-years-human-experimentation-america-tuskegee-study" class="uri">https://www.mcgill.ca/oss/article/history/40-years-human-experimentation-america-tuskegee-study</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>10/25</td>
<td><p>Buolamwini, Joy, and Timnit Gebru. “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.” <em>Conference on Fairness, Accountability and Transparency</em>, PMLR, 2018, pp.&nbsp;77–91. <em>proceedings.mlr.press</em>, <a href="http://proceedings.mlr.press/v81/buolamwini18a.html" class="uri">http://proceedings.mlr.press/v81/buolamwini18a.html</a>.</p>
<p>Castelvecchi, Davide. “Is Facial Recognition Too Biased to Be Let Loose?” <em>Nature</em>, vol.&nbsp;587, no. 7834, 7834, Nature Publishing Group, Nov.&nbsp;2020, pp.&nbsp;347–49. <em>www.nature.com</em>, <a href="https://doi.org/10.1038/d41586-020-03186-4" class="uri">https://doi.org/10.1038/d41586-020-03186-4</a>.</p>
<p>MIT Media Lab. <em>Gender Shades</em>. 2018. <em>YouTube</em>, <a href="https://www.youtube.com/watch?v=TWWsW1w-BVo" class="uri">https://www.youtube.com/watch?v=TWWsW1w-BVo</a>.</p>
<p>Noorden, Richard Van. “The Ethical Questions That Haunt Facial-Recognition Research.” <em>Nature</em>, vol.&nbsp;587, no. 7834, 7834, Nature Publishing Group, Nov.&nbsp;2020, pp.&nbsp;354–58. <em>www.nature.com</em>, <a href="https://doi.org/10.1038/d41586-020-03187-3" class="uri">https://doi.org/10.1038/d41586-020-03187-3</a>.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>10/27</td>
<td><p>Angwin, Julia, et al.&nbsp;“Machine Bias.” <em>ProPublica</em>, 23 May 2016, <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing?token=jRdnwabwdw5HLiHY-R3nqWS5DOjEM7W-" class="uri">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing?token=jRdnwabwdw5HLiHY-R3nqWS5DOjEM7W-</a>.</p>
<p>Hill, Kashmir. “Wrongfully Accused by an Algorithm.” <em>The New York Times</em>, 24 June 2020. <em>NYTimes.com</em>, <a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html" class="uri">https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html</a>.</p>
<p>Lum, Kristian, and William Isaac. “To Predict and Serve?” <em>Significance</em>, vol.&nbsp;13, no. 5, 2016, pp.&nbsp;14–19. <em>Wiley Online Library</em>, <a href="https://doi.org/10.1111/j.1740-9713.2016.00960.x" class="uri">https://doi.org/10.1111/j.1740-9713.2016.00960.x</a>.</p>
<p>O’Neill, James. “How Facial Recognition Makes You Safer.” <em>The New York Times</em>, 9 June 2019. <em>NYTimes.com</em>, <a href="https://www.nytimes.com/2019/06/09/opinion/facial-recognition-police-new-york-city.html" class="uri">https://www.nytimes.com/2019/06/09/opinion/facial-recognition-police-new-york-city.html</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>11/1</td>
<td><p>Arvind Narayanan. <em>Tutorial: 21 Fairness Definitions and Their Politics</em>. 2018. <em>YouTube</em>, <a href="https://www.youtube.com/watch?v=jIXIuYdnyyk" class="uri">https://www.youtube.com/watch?v=jIXIuYdnyyk</a>.</p>
<p>Chouldechova, Alexandra. “Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments.” <em>Big Data</em>, vol.&nbsp;5, no. 2, Mary Ann Liebert, Inc., publishers, June 2017, pp.&nbsp;153–63. <em>liebertpub.com (Atypon)</em>, <a href="https://doi.org/10.1089/big.2016.0047" class="uri">https://doi.org/10.1089/big.2016.0047</a>.</p>
<p>Mitchell, Shira, et al.&nbsp;“Algorithmic Fairness: Choices, Assumptions, and Definitions.” <em>Annual Review of Statistics and Its Application</em>, vol.&nbsp;8, no. 1, 2021, p.&nbsp;null. <em>Annual Reviews</em>, <a href="https://doi.org/10.1146/annurev-statistics-042720-125902" class="uri">https://doi.org/10.1146/annurev-statistics-042720-125902</a>.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>11/3</td>
<td><p>Crawford, Kate. “State.” <em>The Atlas of AI</em>, Yale University Press, 2021, pp.&nbsp;181–209. <em>JSTOR</em>, <a href="https://doi.org/10.2307/j.ctv1ghv45t.9" class="uri">https://doi.org/10.2307/j.ctv1ghv45t.9</a>.</p>
<p>Green, Ben. <em>The Innovative City: The Relationship between Technical and Nontechnical Change in City Government</em>. 2019. <em>direct.mit.edu</em>, <a href="https://direct.mit.edu/books/book/4204/chapter/172388/The-Innovative-City-The-Relationship-between" class="uri">https://direct.mit.edu/books/book/4204/chapter/172388/The-Innovative-City-The-Relationship-between</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>11/8</td>
<td><p>Ingold, David, and Spencer Soper. “Amazon Doesn’t Consider the Race of Its Customers. Should It?” <em>Bloomberg.Com</em>, 21 Apr.&nbsp;2016, <a href="http://www.bloomberg.com/graphics/2016-amazon-same-day/" class="uri">http://www.bloomberg.com/graphics/2016-amazon-same-day/</a>.</p>
<p>MIT Technology Review. <em>Podcast: In Machines We Trust - Hired by an Algorithm</em>. 2021. <em>YouTube</em>, <a href="https://www.youtube.com/watch?v=ztcVB_zh_M0" class="uri">https://www.youtube.com/watch?v=ztcVB_zh_M0</a>.</p>
<p>Raghavan, Manish, and Solon Barocas. “Challenges for Mitigating Bias in Algorithmic Hiring.” <em>Brookings</em>, 6 Dec.&nbsp;2019, <a href="https://www.brookings.edu/research/challenges-for-mitigating-bias-in-algorithmic-hiring/" class="uri">https://www.brookings.edu/research/challenges-for-mitigating-bias-in-algorithmic-hiring/</a>.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>11/10</td>
<td><p>Booth, Robert. “Uber Drivers to Launch Legal Bid to Uncover App’s Algorithm.” <em>The Guardian</em>, 20 July 2020, <a href="http://www.theguardian.com/technology/2020/jul/20/uber-drivers-to-launch-legal-bid-to-uncover-apps-algorithm" class="uri">http://www.theguardian.com/technology/2020/jul/20/uber-drivers-to-launch-legal-bid-to-uncover-apps-algorithm</a>.</p>
<p>Crawford, Kate. “Labor.” <em>The Atlas of AI</em>, Yale University Press, 2021, pp.&nbsp;53–87. <em>JSTOR</em>, <a href="https://doi.org/10.2307/j.ctv1ghv45t.5" class="uri">https://doi.org/10.2307/j.ctv1ghv45t.5</a>.</p>
<p>Gurley, Lauren Kaori. “Amazon Drivers Are Instructed to Drive Recklessly to Meet Delivery Quotas.” <em>VICE</em>, 6 May 2021, <a href="https://www.vice.com/en/article/xgxx54/amazon-drivers-are-instructed-to-drive-recklessly-to-meet-delivery-quotas" class="uri">https://www.vice.com/en/article/xgxx54/amazon-drivers-are-instructed-to-drive-recklessly-to-meet-delivery-quotas</a>.</p>
<p>The Financial Times. <em>The Uber Game</em>. 2020, <a href="https://ig.ft.com/uber-game" class="uri">https://ig.ft.com/uber-game</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>11/15</td>
<td><p>Eubanks, Virginia. “A Child Abuse Prediction Model Fails Poor Families.” <em>Wired</em>, Jan.&nbsp;2018. <em>www.wired.com</em>, <a href="https://www.wired.com/story/excerpt-from-automating-inequality/" class="uri">https://www.wired.com/story/excerpt-from-automating-inequality/</a>.</p>
<p>Gilman, Michele. <em>Poverty Lawgorithms</em>. Data &amp; Society, 15 Sept.&nbsp;2020, <a href="https://datasociety.net/library/poverty-lawgorithms/" class="uri">https://datasociety.net/library/poverty-lawgorithms/</a>.</p>
<p>Henriques-Gomes, Luke. “The Automated System Leaving Welfare Recipients Cut off with Nowhere to Turn.” <em>The Guardian</em>, 16 Oct.&nbsp;2019, <a href="http://www.theguardian.com/technology/2019/oct/16/automated-messages-welfare-australia-system" class="uri">http://www.theguardian.com/technology/2019/oct/16/automated-messages-welfare-australia-system</a>.</p>
<p>Sudhir, K., and Shyam Sunder. “What Happens When a Billion Identities Are Digitized?” <em>Yale Insights</em>, 27 Mar.&nbsp;2020, <a href="https://insights.som.yale.edu/insights/what-happens-when-billion-identities-are-digitized" class="uri">https://insights.som.yale.edu/insights/what-happens-when-billion-identities-are-digitized</a>.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>11/17</td>
<td><p>Chen, Irene Y., et al.&nbsp;“Ethical Machine Learning in Healthcare.” <em>Annual Review of Biomedical Data Science</em>, vol.&nbsp;4, no. 1, 2021, p.&nbsp;null. <em>Annual Reviews</em>, <a href="https://doi.org/10.1146/annurev-biodatasci-092820-114757" class="uri">https://doi.org/10.1146/annurev-biodatasci-092820-114757</a>.</p>
<p>Obermeyer, Ziad, et al.&nbsp;“Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations.” <em>Science</em>, vol.&nbsp;366, no. 6464, American Association for the Advancement of Science, Oct.&nbsp;2019, pp.&nbsp;447–53. <em>www-science-org.offcampus.lib.washington.edu (Atypon)</em>, <a href="https://doi.org/10.1126/science.aax2342" class="uri">https://doi.org/10.1126/science.aax2342</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>11/22</td>
<td><p>Jeffrey Mervis. “Can a Set of Equations Keep U.S. Census Data Private?” <em>ScienceInsider</em>, 4 Jan.&nbsp;2019, <a href="https://www.science.org/content/article/can-set-equations-keep-us-census-data-private" class="uri">https://www.science.org/content/article/can-set-equations-keep-us-census-data-private</a>.</p>
<p>Wezerek, Gus, and David Van Riper. “Opinion | Changes to the Census Could Make Small Towns Disappear.” <em>The New York Times</em>, 6 Feb.&nbsp;2020. <em>NYTimes.com</em>, <a href="https://www.nytimes.com/interactive/2020/02/06/opinion/census-algorithm-privacy.html" class="uri">https://www.nytimes.com/interactive/2020/02/06/opinion/census-algorithm-privacy.html</a>.</p>
<p>Wolford, Ben. “What Is GDPR, the EU’s New Data Protection Law?” <em>GDPR.Eu</em>, 7 Nov.&nbsp;2018, <a href="https://gdpr.eu/what-is-gdpr/" class="uri">https://gdpr.eu/what-is-gdpr/</a>.</p>
<p>Wood, Alexandra, et al.&nbsp;“Differential Privacy: A Primer for a Non-Technical Audience.” <em>Vanderbilt Journal of Entertainment &amp; Technology Law</em>, vol.&nbsp;21, no. 1, 2018, pp.&nbsp;209–75.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>11/24</td>
<td>NO CLASS</td>
<td></td>
</tr>
<tr class="even">
<td>11/29</td>
<td><p>Green, Ben. “The False Promise of Risk Assessments: Epistemic Reform and the Limits of Fairness.” <em>Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</em>, Association for Computing Machinery, 2020, pp.&nbsp;594–606. <em>ACM Digital Library</em>, <a href="https://doi.org/10.1145/3351095.3372869" class="uri">https://doi.org/10.1145/3351095.3372869</a>.</p>
<p>Hooker, Sara. “Moving beyond ‘Algorithmic Bias Is a Data Problem.’” <em>Patterns</em>, vol.&nbsp;2, no. 4, Elsevier, Apr.&nbsp;2021. <em>www.cell.com</em>, <a href="https://doi.org/10.1016/j.patter.2021.100241" class="uri">https://doi.org/10.1016/j.patter.2021.100241</a>.</p>
<p>Raji, Inioluwa Deborah, and Joy Buolamwini. “Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products.” <em>Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society</em>, Association for Computing Machinery, 2019, pp.&nbsp;429–35. <em>ACM Digital Library</em>, <a href="https://doi.org/10.1145/3306618.3314244" class="uri">https://doi.org/10.1145/3306618.3314244</a>.</p>
<p>Upchurch, Tom. “To Work for Society, Data Scientists Need a Hippocratic Oath with Teeth.” <em>Wired UK</em>. <em>www.wired.co.uk</em>, <a href="https://www.wired.co.uk/article/data-ai-ethics-hippocratic-oath-cathy-o-neil-weapons-of-math-destruction" class="uri">https://www.wired.co.uk/article/data-ai-ethics-hippocratic-oath-cathy-o-neil-weapons-of-math-destruction</a>. Accessed 10 May 2021.</p></td>
<td></td>
</tr>
<tr class="odd">
<td>12/1</td>
<td><p>Campbell, Alexia Fernández. “How Tech Employees Are Pushing Silicon Valley to Put Ethics before Profit.” <em>Vox</em>, Oct.&nbsp;2018, <a href="https://www.vox.com/technology/2018/10/18/17989482/google-amazon-employee-ethics-contracts" class="uri">https://www.vox.com/technology/2018/10/18/17989482/google-amazon-employee-ethics-contracts</a>.</p>
<p>Heilweil, Rebecca. “Facebook Is Taking a Hard Look at Racial Bias in Its Algorithms.” <em>Vox</em>, July 2020, <a href="https://www.vox.com/recode/2020/7/22/21334051/facebook-news-feed-instagram-algorithm-racial-bias-civil-rights-audit" class="uri">https://www.vox.com/recode/2020/7/22/21334051/facebook-news-feed-instagram-algorithm-racial-bias-civil-rights-audit</a>.</p>
<p>Mullainathan, Sendhil. “Biased Algorithms Are Easier to Fix Than Biased People.” <em>The New York Times</em>, 6 Dec.&nbsp;2019. <em>NYTimes.com</em>, <a href="https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html" class="uri">https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html</a>.</p>
<p>NIckelsburg, Monica. “Washington State Lawmakers Seek to Ban Government from Using Discriminatory AI Tech.” <em>GeekWire</em>, Feb.&nbsp;2021, <a href="https://www.geekwire.com/2021/washington-state-lawmakers-seek-ban-government-using-ai-tech-discriminates/" class="uri">https://www.geekwire.com/2021/washington-state-lawmakers-seek-ban-government-using-ai-tech-discriminates/</a>.</p>
<p>Richardson, Rashida. <em>Confronting Black Boxes: A Shadow Report of the New York City Automated Decision System Task Force</em>. AI Now Institute, 4 Dec.&nbsp;2019, <a href="https://ainowinstitute.org/ads-shadowreport-2019.html">https:// ainowinstitute.org/ads-shadowreport-2019.html</a>.</p></td>
<td></td>
</tr>
<tr class="even">
<td>12/6</td>
<td></td>
<td>Final Presentations</td>
</tr>
<tr class="odd">
<td>12/8</td>
<td></td>
<td>Final Presentations</td>
</tr>
</tbody>
</table>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>